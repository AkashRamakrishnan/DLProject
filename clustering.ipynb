{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a47e79",
   "metadata": {},
   "source": [
    "# Clustering (poisoned) training data to check for wrong labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc75b75-a462-4ba5-85da-63a4195cd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from clustering_ae import Clustering, utils\n",
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35977971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_model(num_clusters=10, epochs=500):\n",
    "    cae = Clustering(num_clusters=num_clusters,\n",
    "                     n_init=5,\n",
    "                     epochs=epochs,\n",
    "                     tol=1e-5,\n",
    "                     initialization=\"k-means++\"\n",
    "                    )\n",
    "    return cae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b274a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_flat_data(poisoned_train_loader, train_loader, test_loader, save_file):\n",
    "    if os.path.exists(save_file):\n",
    "        print(\"Loading flattened data from saved location...\")\n",
    "        data = np.load(save_file)\n",
    "        return data[\"flat_train_imgs\"], data[\"flat_train_lbls\"], data[\"flat_test_imgs\"], data[\"flat_test_lbls\"], data[\"flat_true_lbls\"]\n",
    "    train_imgs, train_lbls = [], []\n",
    "    test_imgs, test_lbls = [], []\n",
    "    true_lbls = []\n",
    "    for imgs, lbls in tqdm(poisoned_train_loader, desc=\"Flattening poisoned training image\"):\n",
    "        train_imgs.extend(imgs.view(imgs.shape[0], -1).numpy())\n",
    "        train_lbls.extend(lbls.cpu().numpy())\n",
    "    for images, labels in tqdm(train_loader, desc=\"Retrieve true training labels\"):\n",
    "        true_lbls.extend(labels.cpu().numpy())\n",
    "    for imgs, lbls in tqdm(test_loader, desc=\"Flattening testing image\"):\n",
    "        test_imgs.extend(imgs.view(imgs.shape[0], -1).numpy())\n",
    "        test_lbls.extend(lbls.cpu().numpy())\n",
    "    # Save the flattened data\n",
    "    print(\"Saving flattened data to disk...\")\n",
    "    np.savez(save_file,\n",
    "             flat_train_imgs=np.array(train_imgs),\n",
    "             flat_train_lbls=np.array(train_lbls),\n",
    "             flat_test_imgs=np.array(test_imgs),\n",
    "             flat_test_lbls=np.array(test_lbls),\n",
    "             flat_true_lbls=np.array(true_lbls))\n",
    "    return np.array(train_imgs), np.array(train_lbls), np.array(test_imgs), np.array(test_lbls), np.array(true_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1416548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_feature_data(poisoned_train_loader, train_loader, test_loader, device, save_file):\n",
    "    if os.path.exists(save_file):\n",
    "        print(\"Loading feature data from saved location...\")\n",
    "        data = np.load(save_file)\n",
    "        return data[\"feature_train_imgs\"], data[\"feature_train_lbls\"], data[\"feature_test_imgs\"], data[\"feature_test_lbls\"], data[\"feature_true_lbls\"]\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_FEATURES).to(device)\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Initialize the lists to store the feature data\n",
    "    train_imgs, train_lbls = [], []\n",
    "    test_imgs, test_lbls = [], []\n",
    "    true_lbls = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(poisoned_train_loader, desc=\"Retrieve poisoned training image features\"):\n",
    "            # Convert the single channel images to 3 channel\n",
    "            images = torch.repeat_interleave(images.to(device), 3, dim=1)\n",
    "            images = F.interpolate(images, size=(32, 32), mode='nearest')\n",
    "            features_batch = model.features(images).squeeze()\n",
    "            train_imgs.append(features_batch.cpu().detach().numpy())\n",
    "            train_lbls.extend(labels.cpu().numpy())\n",
    "    for images, labels in tqdm(train_loader, desc=\"Retrieve true training labels\"):\n",
    "        true_lbls.extend(labels.cpu().numpy())\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Retrieve testing image features\"):\n",
    "            # Convert the single channel images to 3 channel\n",
    "            images = torch.repeat_interleave(images.to(device), 3, dim=1)\n",
    "            images = F.interpolate(images, size=(32, 32), mode='nearest')\n",
    "            features_batch = model.features(images).squeeze()\n",
    "            test_imgs.append(features_batch.cpu().detach().numpy())\n",
    "            test_lbls.extend(labels.cpu().numpy())\n",
    "    # Save the feature data\n",
    "    print(\"Saving feature data to disk...\")\n",
    "    np.savez(save_file,\n",
    "             feature_train_imgs=np.concatenate(train_imgs),\n",
    "             feature_train_lbls=np.array(train_lbls),\n",
    "             feature_test_imgs=np.concatenate(test_imgs),\n",
    "             feature_test_lbls=np.array(test_lbls),\n",
    "             feature_true_lbls=np.array(true_lbls))\n",
    "    return np.concatenate(train_imgs), np.array(train_lbls), np.concatenate(test_imgs), np.array(test_lbls), np.array(true_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster(poisoned_train_loader, train_loader, test_loader, model_type, device, save_dir, n_components=10, display_cluster=True):\n",
    "    if model_type == \"flat\":\n",
    "        train_imgs, train_lbls, test_imgs, test_lbls, true_lbls = retrieve_flat_data(poisoned_train_loader, train_loader, test_loader, os.path.join(save_dir, \"flat_features.npz\"))\n",
    "    elif model_type == \"feature\":\n",
    "        train_imgs, train_lbls, test_imgs, test_lbls, true_lbls = retrieve_feature_data(poisoned_train_loader, train_loader, test_loader, device, os.path.join(save_dir, \"vgg16_features.npz\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type argument: {model_type}. Has to be either \\\"flat\\\" or \\\"feature\\\".\")\n",
    "\n",
    "    print(\"Clustering the data...\")\n",
    "    # Create the cluster model\n",
    "    cae = create_cluster_model()\n",
    "    # Encode the images\n",
    "    encoded_train_imgs, encoded_test_imgs = utils.encodePCA(train_imgs, test_imgs, n_components-1)\n",
    "    cae.train(encoded_train_imgs)\n",
    "    train_benchmark = cae.benchmark(f'Fashion MNIST - {model_type} {n_components} Components - Train Data', encoded_train_imgs, train_lbls)\n",
    "    test_benchmark = cae.benchmark(f'Fashion MNIST - {model_type} {n_components} Components - Test Data', encoded_test_imgs, test_lbls)\n",
    "    print(f'Fashion MNIST - {model_type} {n_components} Components - ACCURACY: {utils.clustering_accuracy(true_lbls, cae.model.labels_)}')\n",
    "    if display_cluster:\n",
    "        utils.plot(encoded_train_imgs, cae.model.labels_, \"2d\")\n",
    "    return cae, train_benchmark, test_benchmark, encoded_test_imgs, test_lbls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eded2f99aeb90719e888b4c5be52669e449fec0a21fe7ddff5c2d5ec2cc4c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
