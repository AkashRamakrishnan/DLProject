{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b9056",
   "metadata": {},
   "source": [
    "# CNN Posion Attack and Defense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8bbf9c",
   "metadata": {},
   "source": [
    "#### Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f9d309-cb87-4471-9a20-9e8c72bff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helper import print_accuracy\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data.sampler import SubsetRandomSampler  #for validation test\n",
    "\n",
    "%run clustering.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489503ad",
   "metadata": {},
   "source": [
    "#### Setup the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd0c7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the device to cuda:2...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available, if not, check if CUDA is available, if not, CPU\n",
    "device = torch.device('cpu')\n",
    "display_devices = False\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    # If cuda is available...\n",
    "    if torch.cuda.is_available():\n",
    "        # Find GPU with most free memory and set that as the device\n",
    "        mem_usage_list = [torch.cuda.mem_get_info(f'cuda:{gpu_num}')[0] for gpu_num in range(torch.cuda.device_count())]\n",
    "        most_free = mem_usage_list.index(max(mem_usage_list))\n",
    "        device = torch.device(f'cuda:{most_free}')\n",
    "        print(f'Setting the device to {device}...\\n')\n",
    "\n",
    "        if display_devices:\n",
    "            # Print GPU info on all\n",
    "            for gpu_num in range(torch.cuda.device_count()):\n",
    "                available_mem, total_mem = torch.cuda.mem_get_info(f'cuda:{gpu_num}')\n",
    "                print(f'cuda:{gpu_num}')\n",
    "                print('Memory Usage:')\n",
    "                print('Total:', round(total_mem/1024**3,2), 'GB')\n",
    "                print('Allocated:', round((total_mem-available_mem)/1024**3,2), 'GB')\n",
    "                print('Free:   ', round(available_mem/1024**3,2), 'GB')\n",
    "                print()\n",
    "        # Set the default tensor type to gpu\n",
    "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caed69",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334cf3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "MODELS_PATH = os.path.join(WORKING_DIR, \"models\")\n",
    "FEATURES_PATH = os.path.join(WORKING_DIR, \"features\")\n",
    "\n",
    "# Check if the models directory exists, if not, create it\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    os.makedirs(MODELS_PATH)\n",
    "if not os.path.exists(FEATURES_PATH):\n",
    "    os.makedirs(FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c554d7",
   "metadata": {},
   "source": [
    "#### Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d388123-cafd-420b-a1e2-ab9bfc8eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.2859, 0.3530)\n",
    "])\n",
    "\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "\n",
    "# Preparing for validaion test\n",
    "indices = list(range(len(trainset)))\n",
    "np.random.shuffle(indices)\n",
    "# to get 20% of the train set\n",
    "split = int(np.floor(0.2 * len(trainset)))\n",
    "valid_sample = SubsetRandomSampler(indices[:split])\n",
    "train_sample = SubsetRandomSampler(indices[split:])\n",
    "\n",
    "# Data Loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sample, batch_size=64, generator=torch.Generator(device))\n",
    "validloader = torch.utils.data.DataLoader(trainset, sampler=valid_sample, batch_size=64, generator=torch.Generator(device))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True, generator=torch.Generator(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0dcb5",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7fa6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels=6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features = 10)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        # hidden layer 1\n",
    "        tensor = self.conv1(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.max_pool2d(tensor, kernel_size = 2, stride= 2)\n",
    "        # hidden layer 2\n",
    "        tensor = self.conv2(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.max_pool2d(tensor, kernel_size = 2, stride = 2)\n",
    "        # hidden layer 3\n",
    "        tensor = tensor.reshape(-1, 12 * 4* 4)\n",
    "        tensor = self.fc1(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        # hidden layer 4\n",
    "        tensor = self.fc2(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        # output layer\n",
    "        tensor = self.out(tensor)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class EmsembleModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        results = [model(tensor) for model in self.models]\n",
    "        results = torch.stack(results)\n",
    "        results = torch.mean(results, dim=0)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4b522",
   "metadata": {},
   "source": [
    "### Code to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23638498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, optimizer, criterion, epochs, model_path, retrain = False):\n",
    "    train_losses, valid_losses = [], []\n",
    "    predictions_list, labels_list = [], []\n",
    "\n",
    "    # Load the model if retrain is False\n",
    "    if not retrain:\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading model from {model_path}...\")\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            return\n",
    "    # Otherwise, train the model\n",
    "    print(\"Training model...\")\n",
    "    for e in range(epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        # Iterate over the training data\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            # Move the data to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            # Backward pass\n",
    "            if torch.cuda.is_available():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        else:\n",
    "            # Set the model to evaluation mode\n",
    "            model.eval()\n",
    "            valid_loss, correct = 0, 0\n",
    "            total = 0\n",
    "            # Iterate over the validation data\n",
    "            with torch.no_grad():\n",
    "                for images, labels in valid_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    output = model(images)\n",
    "                    valid_loss += criterion(output, labels).item()\n",
    "                    correct += torch.sum(torch.argmax(output, dim=1) == labels).item()\n",
    "                    total += len(labels)\n",
    "            accuracy = correct / total\n",
    "            # Save the model if the validation loss is the lowest so far\n",
    "            print(f\"Epoch: {e+1}/{epochs}  Training loss: {train_loss/len(train_loader):.4f}  Validation loss: {valid_loss/len(valid_loader):.4f}  Validation accuracy: {accuracy:.4f}\")\n",
    "            torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014aca95",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df81f2",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8225fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_cnn_model = FashionCNN().to(device)\n",
    "optimizer = torch.optim.Adam(base_cnn_model.parameters(), lr = 0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(base_cnn_model)  # print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1675d16f-c5c9-42bc-9f0e-8354bb13e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/jovyan/DL/DLProject/models/base_model.pt...\n",
      "Accuracy of T-shirt/Top: 81.40%\n",
      "Accuracy of Trouser: 96.70%\n",
      "Accuracy of Pullover: 77.90%\n",
      "Accuracy of Dress: 91.20%\n",
      "Accuracy of Coat: 83.20%\n",
      "Accuracy of Sandal: 93.70%\n",
      "Accuracy of Shirt: 65.00%\n",
      "Accuracy of Sneaker: 97.50%\n",
      "Accuracy of Bag: 96.80%\n",
      "Accuracy of Ankle Boot: 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(base_cnn_model, trainloader, validloader, optimizer, criterion, 10, os.path.join(MODELS_PATH, 'base_model.pt'))\n",
    "# Print the accuracy of the model\n",
    "print_accuracy(base_cnn_model, testloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123e301",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fface441",
   "metadata": {},
   "source": [
    "## Training with Poisoned Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc7515",
   "metadata": {},
   "source": [
    "- knowledge-oblivious–the attacker shall have no knowledge of the target model’s parameters/structures, nor the original training datasets, \n",
    "\n",
    "- cleanlabel–the attacker shall not be able to control the labeling process, and\n",
    "\n",
    "- clean-test–test-time instances shall not be required to be modified using added adversarial perturbations for attacking effectiveness (https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720137.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eb98bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\"\n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de287cf-fada-4e9a-97ca-5105fd9acf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poison_dataset(x_train, y_train, size_of_infected):\n",
    "    # generate the infected random indices from the training sample\n",
    "    generatePoisonIdx = np.random.choice(len(x_train), size=(size_of_infected,), replace=False)\n",
    "    # generate normal indices excluding from the training sample\n",
    "    trainIdx = np.array([i for i in range(len(x_train)) if i not in generatePoisonIdx])\n",
    "\n",
    "    # indexing all the infected\n",
    "    x_pois_train, y_pois_train = x_train[generatePoisonIdx], y_train[generatePoisonIdx]\n",
    "    # indexing all the noromal\n",
    "    x_train_new, y_train_new = x_train[trainIdx], y_train[trainIdx]\n",
    "\n",
    "    # mix up the labels(infecting the infected)\n",
    "    random_labels = np.random.randint(10, size=size_of_infected)\n",
    "    y_pois_train = np.where(y_pois_train == y_pois_train, random_labels, y_pois_train)\n",
    "\n",
    "    x_poison_train = np.concatenate((x_train_new, x_pois_train))\n",
    "    y_poison_train = np.concatenate((y_train_new, y_pois_train))\n",
    "\n",
    "    print(\"Training samples after infection : \", x_poison_train.shape)\n",
    "    print(\"Labels samples after infection : \", y_poison_train.shape)\n",
    "\n",
    "    return x_poison_train, y_poison_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f6a64f-719e-4949-b75a-4c94b1cac724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after infection :  (60000, 28, 28)\n",
      "Labels samples after infection :  (60000,)\n"
     ]
    }
   ],
   "source": [
    "transform_new = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.2859, 0.3530)\n",
    "])\n",
    "\n",
    "x_poison_train, y_poison_train = create_poison_dataset(trainset.data, trainset.targets, 20000)\n",
    "\n",
    "dataset = FashionDataset(x_poison_train, y_poison_train, transform_new)\n",
    "\n",
    "# Preparing for validaion test\n",
    "indices = list(range(len(dataset)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# to get 20% of the train set\n",
    "split = int(np.floor(0.2 * len(dataset)))\n",
    "valid_sample = SubsetRandomSampler(indices[:split])\n",
    "train_sample = SubsetRandomSampler(indices[split:])\n",
    "\n",
    "# Data Loader\n",
    "poisoned_trainloader = torch.utils.data.DataLoader(dataset, sampler=train_sample, batch_size=64, generator=torch.Generator(device))\n",
    "poisoned_validloader = torch.utils.data.DataLoader(dataset, sampler=valid_sample, batch_size=64, generator=torch.Generator(device))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 12, shuffle = True, generator=torch.Generator(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "279e28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "poisoned_cnn_model = FashionCNN().to(device)\n",
    "optimizer = torch.optim.Adam(poisoned_cnn_model.parameters(), lr = 0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(poisoned_cnn_model)  # print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31480824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/jovyan/DL/DLProject/models/poisoned_model.pt...\n",
      "Accuracy of T-shirt/Top: 77.10%\n",
      "Accuracy of Trouser: 95.50%\n",
      "Accuracy of Pullover: 80.00%\n",
      "Accuracy of Dress: 91.00%\n",
      "Accuracy of Coat: 71.60%\n",
      "Accuracy of Sandal: 92.70%\n",
      "Accuracy of Shirt: 59.80%\n",
      "Accuracy of Sneaker: 96.70%\n",
      "Accuracy of Bag: 95.20%\n",
      "Accuracy of Ankle Boot: 94.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(\n",
    "    poisoned_cnn_model, poisoned_trainloader, poisoned_validloader,\n",
    "    optimizer, criterion, 10,\n",
    "    os.path.join(MODELS_PATH, 'poisoned_model.pt')\n",
    ")\n",
    "# Print the accuracy of the model\n",
    "print_accuracy(poisoned_cnn_model, testloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d814ce",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008540d",
   "metadata": {},
   "source": [
    "## Defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627598f8-7fba-4119-a810-cc4928fbe97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For defense, we will not split the validation set\n",
    "poisoned_full_trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, generator=torch.Generator(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0454dfa",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "Using Auto Encoders to cluster the poisoned data and find the labels/accuracy improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1993ee9",
   "metadata": {},
   "source": [
    "##### Clustering with Flattening\n",
    "Simply flattening before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc8c47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature data from saved location...\n",
      "Clustering the data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components cannot be larger than min(n_features, n_classes - 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclustering.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_benchmark, test_benchmark \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoisoned_full_trainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFEATURES_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/ipykernel_21730/4111295261.py:19\u001b[0m, in \u001b[0;36mtrain_cluster\u001b[0;34m(train_loader, test_loader, model_type, cluster_type, device, save_dir, n_components)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_benchmark, test_benchmark\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cluster_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     train_imgs_LDA, test_imgs_LDA \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencodeLDA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lbls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     cae\u001b[38;5;241m.\u001b[39mtrain(train_imgs_LDA)\n\u001b[1;32m     21\u001b[0m     train_benchmark \u001b[38;5;241m=\u001b[39m cae\u001b[38;5;241m.\u001b[39mbenchmark(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFashion MNIST - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Components - Train Data\u001b[39m\u001b[38;5;124m'\u001b[39m, train_imgs_LDA, train_lbls)\n",
      "File \u001b[0;32m~/DL/DLProject/clustering_ae/utils.py:60\u001b[0m, in \u001b[0;36mencodeLDA\u001b[0;34m(train_features, train_labels, test_features, components)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mReturns a LDA-encoded feature tensor.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    The LDA-encoded test features with `components`-dimension.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m lda \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[38;5;241m=\u001b[39mcomponents)\n\u001b[0;32m---> 60\u001b[0m enc_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mlda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m enc_test_features \u001b[38;5;241m=\u001b[39m lda\u001b[38;5;241m.\u001b[39mtransform(test_features)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enc_train_features, enc_test_features\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/base.py:862\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:608\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m max_components:\n\u001b[0;32m--> 608\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         )\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."
     ]
    }
   ],
   "source": [
    "%run clustering.ipynb\n",
    "train_benchmark, test_benchmark = train_cluster(poisoned_full_trainloader, testloader, \"feature\", \"lda\", device, FEATURES_PATH, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ccfa310-1f73-419a-a2ff-8fe08308c6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fashion MNIST - feature pca 10 Components - Train Data\\t0.00s\\t1.513\\t\\t0.233\\t\\t10900.201\\t\\t0.213\\t\\t0.176\\t\\t0.401',\n",
       " {'name': 'Fashion MNIST - feature pca 10 Components - Train Data',\n",
       "  'duration': 0.0027921199798583984,\n",
       "  'ari': 0.17567157056882288,\n",
       "  'nmi': 0.21300690867969255,\n",
       "  'dbi': 1.512828719035594,\n",
       "  'silhouette': 0.23286471,\n",
       "  'ch_score': 10900.2007063875,\n",
       "  'clustering_accuracy': 0.401})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bbf93",
   "metadata": {},
   "source": [
    "##### Clustering with Feature Extraction\n",
    "Use VGG16 to extract features from images before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2c1e62",
   "metadata": {},
   "source": [
    "### Emsemble Learning\n",
    "Using multiple smaller models to train on the poisoned dataset. The mean accuracy of the models can represent the true accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810234b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eded2f99aeb90719e888b4c5be52669e449fec0a21fe7ddff5c2d5ec2cc4c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
