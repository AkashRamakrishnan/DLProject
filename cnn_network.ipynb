{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63f9d309-cb87-4471-9a20-9e8c72bff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data.sampler import  SubsetRandomSampler  #for validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cd0c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available, if not, check if CUDA is available, if not, use CPU\n",
    "if not torch.backends.mps.is_available():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:1\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d388123-cafd-420b-a1e2-ab9bfc8eed13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.2859, 0.3530)\n",
    "                               ])\n",
    "\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "\n",
    "#Preparing for validaion test\n",
    "indices = list(range(len(trainset)))\n",
    "np.random.shuffle(indices)\n",
    "#to get 20% of the train set\n",
    "split = int(np.floor(0.2 * len(trainset)))\n",
    "valid_sample = SubsetRandomSampler(indices[:split])\n",
    "train_sample = SubsetRandomSampler(indices[split:])\n",
    "\n",
    "#Data Loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, sampler=train_sample, batch_size=64)\n",
    "validloader = torch.utils.data.DataLoader(trainset, sampler=valid_sample, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)\n",
    "\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4492473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper functions\n",
    "def get_item(preds, labels):\n",
    "    \"\"\"function that returns the accuracy of our architecture\"\"\"\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "@torch.no_grad() # turn off gradients during inference for memory effieciency\n",
    "def get_all_preds(network, dataloader):\n",
    "    \"\"\"function to return the number of correct predictions across data set\"\"\"\n",
    "    all_preds = torch.tensor([])\n",
    "    model = network\n",
    "    for batch in dataloader:\n",
    "        images, labels = batch\n",
    "        preds = model(images) # get preds\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0) # join along existing axis\n",
    "        \n",
    "    return all_preds\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7fa6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels=6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features = 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        \n",
    "        # hidden layer 1\n",
    "        tensor = self.conv1(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.max_pool2d(tensor, kernel_size = 2, stride= 2)\n",
    "        \n",
    "        # hidden layer 2\n",
    "        \n",
    "        tensor = self.conv2(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.max_pool2d(tensor, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        #hidden layer 3\n",
    "        \n",
    "        tensor = tensor.reshape(-1, 12 * 4* 4)\n",
    "        tensor = self.fc1(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        \n",
    "        #hidden layer 4\n",
    "        \n",
    "        tensor = self.fc2(tensor)\n",
    "        tensor = F.relu(tensor)\n",
    "        \n",
    "        #output layer\n",
    "        \n",
    "        tensor = self.out(tensor)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8225fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_model = FashionCNN().to(device)\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr = 0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(cnn_model) # print model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1675d16f-c5c9-42bc-9f0e-8354bb13e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.. Training loss: 0.541.. Validation loss: 0.392.. Validation Accuracy: 85.567\n",
      "Epoch: 2/10.. Training loss: 0.377.. Validation loss: 0.344.. Validation Accuracy: 87.308\n",
      "Epoch: 3/10.. Training loss: 0.340.. Validation loss: 0.336.. Validation Accuracy: 87.533\n",
      "Epoch: 4/10.. Training loss: 0.321.. Validation loss: 0.342.. Validation Accuracy: 87.825\n",
      "Epoch: 5/10.. Training loss: 0.308.. Validation loss: 0.338.. Validation Accuracy: 87.692\n",
      "Epoch: 6/10.. Training loss: 0.297.. Validation loss: 0.348.. Validation Accuracy: 87.600\n",
      "Epoch: 7/10.. Training loss: 0.289.. Validation loss: 0.344.. Validation Accuracy: 87.750\n",
      "Epoch: 8/10.. Training loss: 0.277.. Validation loss: 0.341.. Validation Accuracy: 87.642\n",
      "Epoch: 9/10.. Training loss: 0.275.. Validation loss: 0.319.. Validation Accuracy: 88.267\n",
      "Epoch: 10/10.. Training loss: 0.272.. Validation loss: 0.350.. Validation Accuracy: 87.442\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "epochs = 10\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list, labels_list = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = cnn_model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    valid_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      cnn_model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in validloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        log_ps = cnn_model(images)\n",
    "        valid_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        predictions = torch.max(log_ps, 1)[1].to(device)\n",
    "        predictions_list.append(predictions)\n",
    "        correct += (predictions == labels).sum()\n",
    "        total += len(labels)\n",
    "    \n",
    "    accuracy = correct * 100 / total\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    cnn_model.train()\n",
    "    \n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Validation loss: {:.3f}..\".format(valid_loss/len(validloader)),\n",
    "          \"Validation Accuracy: {:.3f}\".format(accuracy))\n",
    "    torch.save(cnn_model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f0fb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5790974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/Top: 85.40%\n",
      "Accuracy of Trouser: 96.30%\n",
      "Accuracy of Pullover: 67.00%\n",
      "Accuracy of Dress: 90.60%\n",
      "Accuracy of Coat: 92.00%\n",
      "Accuracy of Sandal: 94.60%\n",
      "Accuracy of Shirt: 51.70%\n",
      "Accuracy of Sneaker: 96.90%\n",
      "Accuracy of Bag: 97.40%\n",
      "Accuracy of Ankle Boot: 95.20%\n"
     ]
    }
   ],
   "source": [
    "class_correct = [0. for _ in range(10)]\n",
    "total_correct = [0. for _ in range(10)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        test = Variable(images)\n",
    "        outputs = cnn_model(test)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            total_correct[label] += 1\n",
    "        \n",
    "for i in range(10):\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 / total_correct[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fface441",
   "metadata": {},
   "source": [
    "# Training with Poisoned Attack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43fc7515",
   "metadata": {},
   "source": [
    "- knowledge-oblivious–the attacker shall have no knowledge of the target model’s parameters/structures, nor the original training datasets, \n",
    "\n",
    "- cleanlabel–the attacker shall not be able to control the labeling process, and\n",
    "\n",
    "- clean-test–test-time instances shall not be required to be modified using added adversarial perturbations for attacking effectiveness (https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720137.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eb98bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self,X,Y, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1de287cf-fada-4e9a-97ca-5105fd9acf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_infected=30000\n",
    "\n",
    "x_train, y_train = trainset.data, trainset.targets\n",
    "\n",
    "#generate the infected random indices from the training sample\n",
    "generatePoisonIdx = torch.from_numpy(np.random.choice(len(x_train), size=(size_of_infected,), replace=False)) #poison index\n",
    "#generate normal indices excluding from the training sample\n",
    "trainIdx = torch.tensor([i for i in range(len(x_train)) if i not in generatePoisonIdx]) #true index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "703a3307-2872-43f2-8bbf-cb6a60acab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing all the infected\n",
    "x_pois_train, y_pois_train = x_train[generatePoisonIdx],y_train[generatePoisonIdx]\n",
    "#indexing all the noromal\n",
    "x_train_new, y_train_new = x_train[trainIdx],y_train[trainIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e331263a-044e-4227-b705-5a827bd9fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after infection :  torch.Size([60000, 28, 28])\n",
      "Labels samples after infection :  torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "#mix up the labels(infecting the infected) \n",
    "for index,value in enumerate(y_pois_train):\n",
    "    randomIdx = np.random.choice(10)\n",
    "    if randomIdx!=value.item():\n",
    "        y_pois_train[index]=randomIdx\n",
    "    else:\n",
    "        randomIdx = np.random.choice(10)\n",
    "        y_pois_train[index]=randomIdx\n",
    "        \n",
    "x_poison_train = torch.cat([x_train_new,x_pois_train],dim=0)\n",
    "y_poison_train = torch.cat([y_train_new,y_pois_train],dim=0)\n",
    "\n",
    "print(\"Training samples after infection : \",x_poison_train.size())\n",
    "print(\"Labels samples after infection : \",y_poison_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0f6a64f-719e-4949-b75a-4c94b1cac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_new = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.2859, 0.3530)\n",
    "                               ])\n",
    "\n",
    "dataset = FashionDataset(x_poison_train,y_poison_train,transform_new)\n",
    "\n",
    "# Preparing for validaion test\n",
    "indices = list(range(len(dataset)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "#to get 20% of the train set\n",
    "split = int(np.floor(0.2 * len(dataset)))\n",
    "valid_sample = SubsetRandomSampler(indices[:split])\n",
    "train_sample = SubsetRandomSampler(indices[split:])\n",
    "\n",
    "#Data Loader\n",
    "trainloader = torch.utils.data.DataLoader(dataset, sampler=train_sample, batch_size=64)\n",
    "validloader = torch.utils.data.DataLoader(dataset, sampler=valid_sample, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "47ec4347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.. Training loss: 2.250.. Validation loss: 2.241.. Validation Accuracy: 21.767\n",
      "Epoch: 2/10.. Training loss: 2.239.. Validation loss: 2.235.. Validation Accuracy: 22.175\n",
      "Epoch: 3/10.. Training loss: 2.238.. Validation loss: 2.242.. Validation Accuracy: 21.958\n",
      "Epoch: 4/10.. Training loss: 2.236.. Validation loss: 2.243.. Validation Accuracy: 21.475\n",
      "Epoch: 5/10.. Training loss: 2.237.. Validation loss: 2.241.. Validation Accuracy: 21.858\n",
      "Epoch: 6/10.. Training loss: 2.234.. Validation loss: 2.244.. Validation Accuracy: 21.533\n",
      "Epoch: 7/10.. Training loss: 2.233.. Validation loss: 2.243.. Validation Accuracy: 22.225\n",
      "Epoch: 8/10.. Training loss: 2.231.. Validation loss: 2.245.. Validation Accuracy: 21.700\n",
      "Epoch: 9/10.. Training loss: 2.230.. Validation loss: 2.246.. Validation Accuracy: 22.058\n",
      "Epoch: 10/10.. Training loss: 2.228.. Validation loss: 2.250.. Validation Accuracy: 21.558\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "epochs = 10\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list, labels_list = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = cnn_model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    valid_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      cnn_model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in validloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        log_ps = cnn_model(images)\n",
    "        valid_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        predictions = torch.max(log_ps, 1)[1].to(device)\n",
    "        predictions_list.append(predictions)\n",
    "        correct += (predictions == labels).sum()\n",
    "        total += len(labels)\n",
    "    \n",
    "    accuracy = correct * 100 / total\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    cnn_model.train()\n",
    "    \n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Validation loss: {:.3f}..\".format(valid_loss/len(validloader)),\n",
    "          \"Validation Accuracy: {:.3f}\".format(accuracy))\n",
    "    torch.save(cnn_model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f0fb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5790974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/Top: 79.00%\n",
      "Accuracy of Trouser: 95.40%\n",
      "Accuracy of Pullover: 73.30%\n",
      "Accuracy of Dress: 75.90%\n",
      "Accuracy of Coat: 59.30%\n",
      "Accuracy of Sandal: 78.90%\n",
      "Accuracy of Shirt: 26.40%\n",
      "Accuracy of Sneaker: 90.10%\n",
      "Accuracy of Bag: 83.30%\n",
      "Accuracy of Ankle Boot: 82.60%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class_correct = [0. for _ in range(10)]\n",
    "total_correct = [0. for _ in range(10)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        test = Variable(images)\n",
    "        outputs = cnn_model(test)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            total_correct[label] += 1\n",
    "        \n",
    "for i in range(10):\n",
    "    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 / total_correct[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a5366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eded2f99aeb90719e888b4c5be52669e449fec0a21fe7ddff5c2d5ec2cc4c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
