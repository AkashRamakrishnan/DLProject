{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "63f9d309-cb87-4471-9a20-9e8c72bff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adc00e-5c98-4f04-9041-72bb82fd3f54",
   "metadata": {},
   "source": [
    "(i)knowledge-oblivious–the attacker shall have no knowledge of the target\n",
    "model’s parameters/structures, nor the original training datasets, \n",
    "\n",
    "(ii) cleanlabel–the attacker shall not be able to control the labeling process, and\n",
    "\n",
    "(iii)clean-test–test-time instances shall not be required to be modified using added\n",
    "adversarial perturbations for attacking effectiveness\n",
    "\n",
    "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720137.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1210b8-cf64-4f9c-8bbf-1bd2ef83378a",
   "metadata": {},
   "source": [
    "Make sure that you do not reuse the data for training, testing and the attack/defence. - prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "c3ea099f-b0a2-4786-9f20-e2b46cc42575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self,X,Y, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "2d388123-cafd-420b-a1e2-ab9bfc8eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                # transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                           \n",
    "                               ])\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True,transform=transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 12, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0545f0d-3c00-4780-91fa-e583c0206cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7d343d-f318-421d-a89f-9e3d04452ac7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Infecting the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "1de287cf-fada-4e9a-97ca-5105fd9acf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = trainset.data, trainset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585028d-f624-460e-94d7-f749920ab8cc",
   "metadata": {},
   "source": [
    "Seperating out the indices for the normal and the infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "d16fdc7d-308c-4812-bd11-5b386e45781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_infected=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "8d241350-3763-4f07-a076-2fb6979be8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the infected random indices from the training sample\n",
    "generatePoisonIdx = torch.from_numpy(np.random.choice(len(x_train), size=(size_of_infected,), replace=False)) #poison index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "67d1bfc3-911b-4292-994f-cc0aecec0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate normal indices excluding from the training sample\n",
    "trainIdx = torch.tensor([i for i in range(len(x_train)) if i not in generatePoisonIdx]) #true index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "703a3307-2872-43f2-8bbf-cb6a60acab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing all the infected\n",
    "x_pois_train, y_pois_train = x_train[generatePoisonIdx],y_train[generatePoisonIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "fb49382a-2987-4cb8-a1af-3edb21ca48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing all the noromal\n",
    "x_train_new, y_train_new = x_train[trainIdx],y_train[trainIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "e331263a-044e-4227-b705-5a827bd9fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mix up the labels(infecting the infected) \n",
    "for index,value in enumerate(y_pois_train):\n",
    "    randomIdx = np.random.choice(10)\n",
    "    if randomIdx!=value.item():\n",
    "        y_pois_train[index]=randomIdx\n",
    "    else:\n",
    "        randomIdx = np.random.choice(10)\n",
    "        y_pois_train[index]=randomIdx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c8f5f-3e27-45c4-8f02-efa979872568",
   "metadata": {},
   "source": [
    "Merging the normal and infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "1ba50691-506e-4692-a6f3-b66ab88abe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_poison_train = torch.cat([x_train_new,x_pois_train], dim=0)\n",
    "y_poison_train = torch.cat([y_train_new,y_pois_train],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfab0e-668f-417f-b4e7-328a35060157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "fd11bdc0-f72c-4f6e-aa79-f41abbb0c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after infection :  torch.Size([60000, 28, 28])\n",
      "Labels samples after infection :  torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples after infection : \",x_poison_train.size())\n",
    "print(\"Labels samples after infection : \",y_poison_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b0f6a64f-719e-4949-b75a-4c94b1cac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_new = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                           \n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "178fb188-cd21-412e-a844-d4a07ef9c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionDataset(x_poison_train,y_poison_train,transform_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a1327-8bf3-4b79-99a6-cfba59e8c6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "134eeaee-efa8-4372-b025-d3e1712d9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 12, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3dd9a-c8ad-45df-815b-86f40fd77d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9805f4ad-fc80-4130-9846-f039810671d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    # print(x.numpy().shape)\n",
    "    plt.imshow(x.numpy().reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "09c37228-1aa7-44b1-bbd0-f34ceb16c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "207ddfd5-3f43-481f-85b8-82be26b6f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "      \n",
    "                ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "4fd1badf-c681-49b6-a047-201d6339d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.. Training loss: 2.069.. Test loss: 1.324.. Test Accuracy: 0.765\n",
      "Epoch: 2/10.. Training loss: 2.018.. Test loss: 1.366.. Test Accuracy: 0.777\n",
      "Epoch: 3/10.. Training loss: 2.010.. Test loss: 1.308.. Test Accuracy: 0.778\n",
      "Epoch: 4/10.. Training loss: 2.005.. Test loss: 1.246.. Test Accuracy: 0.777\n",
      "Epoch: 5/10.. Training loss: 2.007.. Test loss: 1.249.. Test Accuracy: 0.781\n",
      "Epoch: 6/10.. Training loss: 2.005.. Test loss: 1.264.. Test Accuracy: 0.791\n",
      "Epoch: 7/10.. Training loss: 2.005.. Test loss: 1.284.. Test Accuracy: 0.781\n",
      "Epoch: 8/10.. Training loss: 2.004.. Test loss: 1.317.. Test Accuracy: 0.800\n",
      "Epoch: 9/10.. Training loss: 2.025.. Test loss: 1.194.. Test Accuracy: 0.792\n",
      "Epoch: 10/10.. Training loss: 2.006.. Test loss: 1.304.. Test Accuracy: 0.785\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = [], []\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.view(images.shape[0], -1).to(device)\n",
    "    images.requires_grad = True\n",
    "    labels = labels.to(device)\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        log_ps = model(images)\n",
    "        test_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    model.train()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42055619-9281-407c-a6fb-d6f109276140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
