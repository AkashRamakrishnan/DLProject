{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f9d309-cb87-4471-9a20-9e8c72bff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adc00e-5c98-4f04-9041-72bb82fd3f54",
   "metadata": {},
   "source": [
    "(i)knowledge-oblivious–the attacker shall have no knowledge of the target\n",
    "model’s parameters/structures, nor the original training datasets, \n",
    "\n",
    "(ii) cleanlabel–the attacker shall not be able to control the labeling process, and\n",
    "\n",
    "(iii)clean-test–test-time instances shall not be required to be modified using added\n",
    "adversarial perturbations for attacking effectiveness\n",
    "\n",
    "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720137.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1210b8-cf64-4f9c-8bbf-1bd2ef83378a",
   "metadata": {},
   "source": [
    "Make sure that you do not reuse the data for training, testing and the attack/defence. - prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d388123-cafd-420b-a1e2-ab9bfc8eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 12, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e5bc9e-3a80-43db-866f-2351f48d629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloader))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c37228-1aa7-44b1-bbd0-f34ceb16c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207ddfd5-3f43-481f-85b8-82be26b6f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "                ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd1badf-c681-49b6-a047-201d6339d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10.. Training loss: 0.645.. Test loss: 0.505.. Test Accuracy: 0.817\n",
      "Epoch: 2/10.. Training loss: 0.539.. Test loss: 0.470.. Test Accuracy: 0.836\n",
      "Epoch: 3/10.. Training loss: 0.514.. Test loss: 0.434.. Test Accuracy: 0.840\n",
      "Epoch: 4/10.. Training loss: 0.501.. Test loss: 0.451.. Test Accuracy: 0.840\n",
      "Epoch: 5/10.. Training loss: 0.487.. Test loss: 0.437.. Test Accuracy: 0.838\n",
      "Epoch: 6/10.. Training loss: 0.479.. Test loss: 0.430.. Test Accuracy: 0.853\n",
      "Epoch: 7/10.. Training loss: 0.468.. Test loss: 0.481.. Test Accuracy: 0.836\n",
      "Epoch: 8/10.. Training loss: 0.477.. Test loss: 0.483.. Test Accuracy: 0.834\n",
      "Epoch: 9/10.. Training loss: 0.465.. Test loss: 0.461.. Test Accuracy: 0.850\n",
      "Epoch: 10/10.. Training loss: 0.456.. Test loss: 0.415.. Test Accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = [], []\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    images = images.view(images.shape[0], -1).to(device)\n",
    "    labels = labels.to(device)\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model.forward(images)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "  else:\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # Turn off gradients for validation, saves memory and computation\n",
    "    with torch.no_grad():\n",
    "      # Set the model to evaluation mode\n",
    "      model.eval()\n",
    "      \n",
    "      # Validation pass\n",
    "      for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        log_ps = model(images)\n",
    "        test_loss += criterion(log_ps, labels)\n",
    "        \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    \n",
    "    model.train()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    \n",
    "    print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1675d16f-c5c9-42bc-9f0e-8354bb13e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10.. Training loss: 0.456.. Test loss: 0.415.. Test Accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "          \"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0805cc-c68e-45ff-a522-d3fd21eb9ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7a47e79",
   "metadata": {},
   "source": [
    "# Clustering (poisoned) training data to check for wrong labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2dc75b75-a462-4ba5-85da-63a4195cd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering code\n",
    "\n",
    "from clustering_ae import Clustering\n",
    "\n",
    "cae = Clustering(num_clusters=10,\n",
    "        n_init = 10,\n",
    "        epochs = 3000,\n",
    "        tol = 1e-2,\n",
    "        initialization = \"k-means++\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5293217b-df57-4c19-ab51-7609ad35c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lbls = [], []\n",
    "for images, labels in trainloader:\n",
    "    # Flatten Fashion-MNIST images into a 784 long vector\n",
    "    imgs.extend(images.view(images.shape[0], -1).numpy())\n",
    "    lbls.extend(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae09bb2b-f293-47be-a8b8-66f65f04b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lbls = np.array(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d14b0dd-362a-4485-a8ee-9549b037c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae.train(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0ebae7d-7679-4c91-af08-6f03fa23051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = cae.benchmark('Fashion mnist', imgs, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c150da-b6ed-4d77-be09-6650a27dc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ebe7b718-211a-46a9-97ed-7e69bfc05008",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cae.predict([imgs[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "213b007d-ca4f-431d-a40a-3209424afd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] 8\n"
     ]
    }
   ],
   "source": [
    "print(p, lbls[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12e2a02e-b1ed-46e8-a619-84ab04714dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "for i in range(len(lbls)):\n",
    "    if lbls[i] == 3:\n",
    "        test_imgs.append(imgs[i])\n",
    "\n",
    "preds = cae.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cffaf30-3f91-48be-be30-d6e6499523c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.tolist()\n",
    "pred_dict=dict(zip(preds,[preds.count(i) for i in preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "775549a4-19e7-4653-9c45-851065f7d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 3117, 2: 1720, 4: 340, 1: 738, 3: 55, 8: 17, 5: 1, 9: 9, 7: 3}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04173082-cabe-4dbf-8c02-4b87623ff809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
